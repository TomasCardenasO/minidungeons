# Implementaci√≥n de Agentes Generativos con Q-Learning (Dungeon Crawler)

Este proyecto es una implementaci√≥n en Java de agentes aut√≥nomos basados en **Aprendizaje por Refuerzo (Q-Learning)**. Los agentes aprenden a navegar y tomar decisiones en niveles de un juego tipo *Dungeon Crawler* (mazmorras) bas√°ndose en diferentes "Personas" o estilos de juego.

El c√≥digo implementa la metodolog√≠a descrita en el paper de investigaci√≥n:
**"Generative Agents for Player Decision Modeling in Games"**

El objetivo actual del proyecto es entrenar una personalidad espec√≠fica (**Treasure Collector**) capaz de maximizar la recolecci√≥n de tesoros mientras sobrevive en mapas complejos.

## üìã Caracter√≠sticas del Proyecto

* **Algoritmo Q-Learning Tabular:** Implementaci√≥n desde cero sin librer√≠as externas de ML
* **Personas Procedurales:** Capacidad para entrenar distintos perfiles (Baseline, Runner, Survivalist, Monster Killer, Treasure Collector)
* **Sistema de Checkpoints:** El entrenamiento guarda el progreso peri√≥dicamente, permitiendo pausar y reanudar el proceso sin perder datos. (No implementado)
* **Optimizaci√≥n de Estado:** Representaci√≥n eficiente del mapa usando `StringBuilder` para un entrenamiento r√°pido.
* **Soporte Multi-Mapa:** Capacidad para entrenar y validar agentes en m√∫ltiples niveles (mapas 0 al 10).

## üõ†Ô∏è Requisitos Previos

Para ejecutar este proyecto necesitas:

* **Java JDK 8** o superior.
* **NetBeans IDE** (Recomendado, ya que el proyecto mantiene la estructura de directorios nativa de NetBeans).
* **Git** (para control de versiones).

## üöÄ Instalaci√≥n

1.  **Clonar el Repositorio:**
    Abre tu terminal y ejecuta:
    ```bash
    git clone [https://github.com/TU-USUARIO/TU-REPO.git](https://github.com/TU-USUARIO/TU-REPO.git)
    ```
    *(Reemplaza la URL con el link de tu repositorio)*.

2.  **Abrir en NetBeans:**
    * Inicia NetBeans IDE.
    * Ve a **File > Open Project**.
    * Selecciona la carpeta clonada (deber√≠a tener el icono de taza de caf√© de Java).
    * Haz clic en **Open Project**.

---

## ‚öôÔ∏è Gu√≠a de Ejecuci√≥n

El flujo de trabajo consta de dos fases obligatorias: **1. Entrenamiento** y **2. Simulaci√≥n**.

### Paso 1: Entrenamiento (`QTraining.java`)

El agente nace "en blanco". Debes ejecutar el entrenamiento para que genere su tabla de conocimiento (Q-Table).

1.  En NetBeans, navega a `Source Packages > experiment`.
2.  Haz clic derecho en **`QTraining.java`**.
3.  Selecciona **Run File**.

**¬øQu√© esperar durante el entrenamiento?**
* El sistema entrenar√° al agente en los mapas del **0 al 10**.
* Se ejecutar√°n **250,000 episodios** por cada mapa.
* **Salida:** Al finalizar, se generar√°n archivos `.ser` (ej: `TREASURE_COLLECTOR_map0.ser`) en la carpeta `trained_agents/`.

### Paso 2: Simulaci√≥n (`SimulationMode.java`)

Una vez generados los "cerebros" (`.ser`), puedes ver al agente jugar.

1.  Navega a `Source Packages > experiment`.
2.  Haz clic derecho en **`SimulationMode.java`**.
3.  Selecciona **Run File**.

**Resultados:**
* El programa ejecutar√° 10 partidas de prueba en cada mapa usando el agente entrenado (con `epsilon = 0` para m√°xima eficiencia).
* Se generar√°n reportes y mapas de calor en la carpeta `testResults/`.
* Podr√°s ver en la consola m√©tricas como `treasuresCollected` y `timesCompleted`.

---

## üìÇ Estructura del Directorio

* **`dungeons/`**: Contiene los archivos de texto (`map0.txt` - `map10.txt`) que definen la estructura de los niveles (muros, monstruos, tesoros).
* **`trained_agents/`**: Carpeta generada autom√°ticamente donde se almacenan las pol√≠ticas aprendidas (archivos binarios `.ser`).
* **`testResults/`**: Carpeta de salida para los logs de simulaci√≥n y heatmaps.
* **`src/controllers/`**:
    * `QLearningController.java`: El "cerebro" del agente. Contiene la tabla Q, la l√≥gica de recompensas y la codificaci√≥n del estado.
* **`src/experiment/`**:
    * `QTraining.java`: Script principal para el entrenamiento masivo.
    * `SimulationMode.java`: Script para validar el rendimiento de los agentes entrenados.
